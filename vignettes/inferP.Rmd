---
title: "Probability bounds of logical expressions"
output:
  rmarkdown::html_vignette:
    number_sections: true
vignette: >
  %\VignetteIndexEntry{Probability bounds of logical expressions}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---


$\renewcommand{\P}{\mathrm{P}}$
$\renewcommand{\|}{\:\vert\:\mathopen{}}$
$\newcommand{\mo}{\mathrel{\!=\!}}$

# Introduction

The probability calculus is an extension of the calculus of propositional logic. Besides considering the *truth* or *falsity* of propositions, translated into *certainty* and *impossibility*, the probability calculus also considers a continuum of degrees of certainty -- probabilities -- between these two extremes. Just as propositional logic gives a set of rules to derive the truth or falsity of some propositions from the truth or falsity of others, so the probability calculus gives a set of rules to derive the probability of some propositions from the probability of others; these rules include the logical ones as a special case.

There are different [deduction systems](https://plato.stanford.edu/archives/spr2023/entries/natural-deduction) (each with many dialects) to express the rules of propositional logic; one of them is the *sequent calculus*. The probability calculus has many analogies with the sequent calculus.

In sequent calculus we express that proposition $a$ is true within a set of axioms $I$ by the notation

$$
I \vdash a
$$

The same is expressed in the probability calculus by the notation

$$
\P(a \| I) = 1
$$

but in this case we can also consider degrees of certainty different from $1$.

The theory of "random variables" is a particular application of the probability calculus: an expression such as "$X\mo x$" means "The quantity $X$ is measured to have value $x$" -- which is just a proposition. Also the "causal calculus" is a particular application: an expression such as "$\mathrm{do}(X \mo x)$" means "The quantity $X$ has been *set* equal to $x$" -- which is also just a proposition. In the probability calculus we can in fact even consider more general propositions, such as "The quantity $X$ has been *reported* to be equal to $x$".

\

The view of the probability calculus as an extension of the logical calculus goes back at least to Boole, possibly to Laplace.


# Probabilistic inferences

In propositional logic, suppose we assert that:

- proposition $a$ is true given a set of axioms $I$,
- proposition $b \lor \lnot a$ given the set of axioms $I$ augmented with the proposition $c$.

Then we can also assert that $b$ is true given the set of axioms $c \land I$. This is a logical deduction. In the notation of sequent calculus it is written as follows:

$$
\frac{
I \vdash a \enspace,\enspace I \land c \vdash b \lor \lnot a
}{
I \land c \vdash b
}
$$

The conclusion follows by the application of inference rules, starting from the initial assertions.

In the probability calculus the same inference can be expressed as follows:

$$
\frac{
\P(a \| I) = 1\enspace,\enspace \P(b \lor \lnot a \| c \land I) = 1
}{
\P(b \| c \land I) = 1
}
$$

This final probability can be shown to follow from the initial ones by the well-known probability rules, valid for any sentences $a$, $b$:

- $\P(\lnot a \| I) = 1 - \P(a \| I)$

- $\P(a \land b \| I) = \P(a \| b \land I)\cdot\P(b \| I)
= \P(b \| a \land I)\cdot\P(a \| I)$

- $\P(a \lor b \| I) = \P(a \| I) + \P(b \| I) - \P(a \land b \| I)$

- $\P(a \| a \land I) = 1$


Another simple probability inference, which immediately follows from the rules, is for example

$$
\frac{
\P(a \| I) = 0.3\enspace,\enspace \P(b \| a \land I) = 0.2
}{
\P(a \land b \| I) = 0.06
}
$$

\

The probability rules effectively imply the rules of propositional logic as special cases.

What's remarkable is that **the probability rules allow us to determine the *lower* and *upper* values that a probability can have, under the assertion of the values of other probabilities**. It is well-known, for instance, that if

$$
\P(a \| I) = 0.2\,,
\P(b \| I) = 0.7
$$

then the probability $\P(a \land b \| I)$ cannot be larger than the minimum of the two above, that is,

$$
\P(a \land b \| I) \in [0, 0.2]
$$

It has been shown that finding such bounds is equivalent to solving a linear-optimization problem. The most relevant texts about this equivalence are those by Hailperin, given in the references.

# The function `inferP()`

The function `inferP()` implements the linear-optimization algorithm just mentioned. As a first argument, named `target =`, it takes the probability of an expression of propositional logic, conditional on another one; as optional subsequent arguments it takes constraints about the probabilities of other propositional-logic expressions, for example their numerical values, as in the examples above.

The notation used in the function conforms to R's notation for logical operators, and uses the operator `~` as notation for the conditional bar "${}\|{}$":

- Conditional bar: `~`
- Not: `!`
- And: `&` or `&&`
- Or: `|` or `||`
- If-then: `%>%` ("if $a$ then $b$", `a %>% b`, is simply equivalent to $b \lor \lnot a$)

## Simple examples

Load the package:

``` r
library('Pinference')
```

Here are some examples, from more trivial to more complex.

- The probability of a sentence $a$ can be anything between 0 and 1:

``` r
inferP(
    target = P(a  ~  I)
)
# min max 
#   0   1
```

\

- But if we assume the truth of that sentence, then its probability must be 1:

``` r
inferP(
    target = P(a  ~  a & I)
)
# min max 
#   1   1
```

\

- If we assume the negation of that sentence, then its probability must be 0:

``` r
inferP(
    target = P(a  ~  !a & I)
)
# min max 
#   0   0
```

\

- A probability conditional on contradictory assumptions, such as $b \land \lnot b$, is undefined:

``` r
inferP(
    target = P(a  ~  b & !b & I)
)
# min max 
#  NA  NA
```

\

## Examples with constraints

- This is a statement of the "and" or "multiplication" or "conjunction" rule:

``` r
inferP(
    target = P(a & b  ~  I),
    P(a  ~  I) == 0.2,
    P(b  ~  a & I) == 0.3
)
#  min  max 
# 0.06 0.06
```

- The rule for "conditional probability":

``` r
inferP(
    target = P(b  ~  a & I),
    P(a & b  ~  I) == 0.06,
    P(a  ~  I) == 0.2
)
# min max 
# 0.3 0.3
```

- If we assert that two sentences have the same probability, and the sentences are mutually exclusive and exhaustive, then each must have 0.5 probability:

``` r
inferP(
    target = P(a  ~  I),
    P(a  ~  I) == P(b  ~  I),
    P(a & b  ~  I) == 0,
    P(a | b  ~  I) == 1
)
# min max 
# 0.5 0.5
```

- The logical rule of implication: if $a$ and $a \Rightarrow b$ are true, then $b$ is true:

``` r
inferP(
    target = P(b  ~  I),
    P(a  ~  I) == 1,
    P(a %>% b  ~  I) == 1
)
# min max 
#   1   1
```

- Under a false proposition, any implication is always true:

``` r
inferP(
    target = P(a %>% b  ~  I),
    P(a  ~  I) == 0
)
# min max 
#   1   1
```

## Combining evidence

Suppose that hypothesis $H$ has probability 0.7 given evidence $E_1$, and probability 0.8 given evidence $E_2$. What is its probability if two pieces of evidence are combined, that is, given their conjunction? An interesting result, proven by Hailperin, is that such probability can be anything:

``` r
inferP(
    target = P(H  ~  E1 & E2 & I),
    P(H  ~  E1 & I) == 0.7,
    P(H  ~  E2 & I) == 0.8
)
# min max 
#   0   1
```

# The Monty Hall problem

The "Monty Hall problem", inspired by the TV show *Let's make
  a deal!* hosted by Monty Hall, was proposed in the *Parade* magazine
in 1990 (see Lo Bello 1991). the numbers of the doors are changed here):

> Suppose you are on a game show and given a choice of three doors. Behind one is a car; behind the others are goats. You pick door No. 1, and the host, who knows what is behind them and wouldn't open the door with the car, opens No. 3, which has a goat. He then asks if you want to pick No. 2. Should you switch?

We can solve this problem with `inferP()`.

## Propositions

First let's introduce some notation for the relevant propositions:

- `I`: a proposition expressing the rules of the game,
- `car1`: "The car is behind door No. 1",
- `you1`: "You pick door No. 1",
- `host1`: "The host opens door No. 1",

and similarly for the other doors.

## Target probability

We want to know what's the probability that the car is behind the other door, No. 2.

The conditional of the target probability has, besides the game rules $I$, two propositions expressing the information we have: you chose door No. 1, `you1`, and the host opened door No. 3, `host3`.

The target probability is thus `P(car2  ~  you1 & host3 & I)`

## Given probabilities

We must express the information we have and the game rules in terms of probabilities. Note that there are several equivalent ways to express the probabilistic constraints listed below.

1. We know that there is only one car, and it must be behind one door. This corresponds to four probability constraints:
    
    `P(car1 & car2  ~  I) == 0`    
    `P(car1 & car3  ~  I) == 0`    
    `P(car2 & car3  ~  I) == 0`    
    `P(car1 | car2 | car3  ~  I) == 1`
\

2. The host must open one door, and only one door. But the host cannot open the door you chose, and cannot open the door that has the car, but must open one door. This corresponds to seven probability constraints:
    
    `P(host1 & host2  ~  I) == 0`    
    `P(host1 & host3 ~  I) == 0`    
    `P(host2 & host3  ~  I) == 0`    
    `P(host1 | host2 | host3  ~  I) == 1`    
    `P(host1  ~  you1 & I) == 0`    
    `P(host2  ~  car2 & I) == 0`    
    `P(host3  ~  car3 & I) == 0`    
\

3. Let's say that you are initially equally undecided among the three doors:
    
    `P(car1  ~  I) == P(car2  ~  I)`    
    `P(car2  ~  I) == P(car3  ~  I)`    
\

4. The fact, alone, that you picked door No. 1 is irrelevant to the knowledge about the car's position:
    
    `P(car1  ~  you1 & I) == P(car2  ~  you1 & I)`    
    `P(car2  ~  you1 & I) == P(car3  ~  you1 & I)`    
\

4. Finally, we have no reason to believe that the host favours one door over another, when a choice is possible, that is, when the car is behind the door you chose:
    
    `P(host2  ~  you1 & car1 & I) == P(host3  ~  you1 & car1 & I)`    
\

## Result

We can finally input the desired target and the constraints into `inferP()`:


``` r
inferP(
    target = P(car2  ~  you1 & host3 & I),
    ##
    P(car1 & car2  ~  I) == 0,
    P(car1 & car3  ~  I) == 0,
    P(car2 & car3  ~  I) == 0,
    P(car1 | car2 | car3  ~  I) == 1,
    ##
    P(host1 & host2 ~ I) == 0,
    P(host1 & host3 ~ I) == 0,
    P(host2 & host3 ~ I) == 0,
    P(host1 | host2 | host3  ~  I) == 1,
    P(host1  ~  you1 & I) == 0,
    P(host2  ~  car2 & I) == 0,
    P(host3  ~  car3 & I) == 0,
    ##
    P(car1  ~  I) == P(car2  ~  I),
    P(car2  ~  I) == P(car3  ~  I),
    ##
    P(car1  ~  you1 & I) == P(car2  ~  you1 & I),
    P(car2  ~  you1 & I) == P(car3  ~  you1 & I),
    ##
    P(host2  ~  you1 & car1 & I) == P(host3  ~  you1 & car1 & I)
)
#      min      max 
# 0.666667 0.666667
```

The well-known result is 2/3. You can also check the obvious result for `car3`, which is 0.

## Omitting probability constraints

It is interesting to see what happens to the bounds of the target probability when some constraints are omitted. For instance, suppose that we omit the constraint\
`P(host2  ~  you1 & car1 & I) == P(host3  ~  you1 & car1 & I)`\
which stated that we have no reason to believe the host would choose door No. 2 more than No. 3 or vice versa, when the car is behind door No. 1:


``` r
inferP(
    target = P(car2  ~  you1 & host3 & I),
    ##
    P(car1 & car2  ~  I) == 0,
    P(car1 & car3  ~  I) == 0,
    P(car2 & car3  ~  I) == 0,
    P(car1 | car2 | car3  ~  I) == 1,
    ##
    P(host1 & host2 ~ I) == 0,
    P(host1 & host3 ~ I) == 0,
    P(host2 & host3 ~ I) == 0,
    P(host1 | host2 | host3  ~  I) == 1,
    P(host1 & you1  ~  I) == 0,
    P(host2 & car2  ~  I) == 0,
    P(host3 & car3  ~  I) == 0,
    ##
    P(car1  ~  I) == P(car2  ~  I),
    P(car2  ~  I) == P(car3  ~  I),
    ##
    P(car1  ~  you1 & I) == P(car2  ~  you1 & I),
    P(car2  ~  you1 & I) == P(car3  ~  you1 & I)
    ##
    ## P(host2  ~  you1 & car1 & I) == P(host3  ~  you1 & car1 & I) # omitted
)
# min max 
# 0.5 1.0
```

The probability that the car is behind door No. 2 is in this case undetermined, but it must be more than 1/2. The conclusion is that it is still best to switch door (if you want the car), but our degree of certainty in winning is not 2/3.


## Variations

The internet offers many variations of the Monty Hall problem. They can also be solved with `inferP()`.



``` r
inferP(
    target = P(car2  ~  you1 & host3 & I),
    ##
    P(car1 & car2  ~  I) == 0,
    P(car1 & car3  ~  I) == 0,
    P(car2 & car3  ~  I) == 0,
    P(car1 | car2 | car3  ~  I) == 1,
    ##
    P(you1 & you2  ~  I) == 0,
    P(you1 & you3  ~  I) == 0,
    P(you2 & you3  ~  I) == 0,
    P(you1 | you2 | you3  ~  I) == 1,
    ##
    P(host1 & host2 ~ I) == 0,
    P(host1 & host3 ~ I) == 0,
    P(host2 & host3 ~ I) == 0,
    P(host1 | host2 | host3  ~  I) == 1,
    P(host1 & car1  ~ !you1 & I) == 0.01,
    P(host2 & car2  ~ !you2 &  I) == 0.01,
    P(host3 & car3  ~ !you3 & I) == 0.01,
    P(host1 & you1  ~  I) == 0,
    P(host2 & you2  ~  I) == 0,
    P(host3 & you3  ~  I) == 0,
    ##
    P(car1  ~  I) == P(car2  ~  I),
    P(car2  ~  I) == P(car3  ~  I),
    ##
    P(car1  ~  you1 & I) == P(car2  ~  you1 & I),
    P(car2  ~  you1 & I) == P(car3  ~  you1 & I),
    P(car1  ~  you2 & I) == P(car2  ~  you2 & I),
    P(car2  ~  you2 & I) == P(car3  ~  you2 & I),
    P(car1  ~  you3 & I) == P(car2  ~  you3 & I),
    P(car2  ~  you3 & I) == P(car3  ~  you3 & I),
    ##
    P(host2  ~  you1 & car1 & I) == P(host3  ~  you1 & car1 & I),
    P(host1  ~  you2 & car2 & I) == P(host3  ~  you2 & car2 & I),
    P(host1  ~  you3 & car3 & I) == P(host2  ~  you3 & car3 & I)
)
#      min      max 
# 0.000000 0.666667
```




# Appendices {#appendix}

## References {#references}

### On *exchangeability*: {#referencesexchang}

- Bernardo, Smith: [*Bayesian Theory*](https://doi.org/10.1002/9780470316870) (repr. 2000). See especially §§ 4.2--4.3, 4.6.

- Dawid: [*Exchangeability and its ramifications*](https://doi.org/10.1093/acprof:oso/9780199695607.003.0002) (2013).

- de Finetti: [*La prévision: ses lois logiques, ses sources subjectives*](https://www.numdam.org/item/AIHP_1937__7_1_1_0) (1937).

- Heath, Sudderth: [*De Finetti's theorem on exchangeable variables*](https://doi.org/10.1080/00031305.1976.10479175) (1976).

- Hewitt, Savage: [*Symmetric measures on Cartesian products*](https://doi.org/10.1090/S0002-9947-1955-0076206-8) (1955).

- Lindley, Novick: [*The role of exchangeability in inference*](https://doi.org/10.1214/aos/1176345331) (1981).

- ***inferno*** accompanying manual: [*Foundations of inference under symmetry*](https://github.com/pglpm/inferno/raw/main/development/manual/optimal_predictor_machine.pdf) (draft).

### On Bayesian theory in general: {#referencesbayes}

- Jaynes: [*Probability Theory*](https://doi.org/10.1017/CBO9780511790423) (2003).

- MacKay: [*Information Theory, Inference, and Learning Algorithms*](https://www.inference.org.uk/itila/book.html) (2005).

- [*ADA 511: Foundations of data science*](https://pglpm.github.io/ADA511).

### On medical decision-making: {#referencesmedical}

- Sox, Higgins, Owens, Sanders Schmidler: [*Medical Decision Making*](https://doi.org/10.1002/9781119627876) (3rd ed. 2024).

- Hunink, Weinstein, Wittenberg, Drummond, Pliskin, Wong, Glasziou: [*Decision Making in Health and Medicine: Integrating Evidence and Values*](https://doi.org/10.1017/CBO9781139506779) (2nd ed. 2014).

\

## Format for data and metadata files and their contents {#format}

The functions of the ***inferno*** package accept CSV files formatted as follows:

- Decimal values should be separated by a *dot*; no comma should be used to separate thousands etc. Example: `86342.75` .
- Character and names should be quoted in single or double quotes. Example: `"female"`.
- Values should be separated by *commas*, not by tabs or semicolons.
- Missing values should be simply *empty*, not denoted by "NA", "missing", "-", or similar.

Names of variates and character variate values should be strings conforming to [R's rules](https://cran.r-project.org/doc/FAQ/R-FAQ.html#What-are-valid-names_003f).

